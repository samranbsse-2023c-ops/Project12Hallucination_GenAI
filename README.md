# Project 12: Hallucination in Generative AI Code Outputs

## Overview
This project studies hallucinations in code generated by LLMs (Code LLaMA, StarCoder, LLaMA variants)
and proposes mitigation strategies.

## Repository Structure
- `LaTeX/` - Source file for research paper
- `PDF_Report/` - PDF report
- `Code/` - Python code with test-driven validation
- `Screenshots/` - Training, evaluation, and hallucination metrics

## How to Run Code
```bash
cd Code
python hallucination_detection.py

